{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"300\" src=\"libraries_short_color.png\" alt=\"NYU Libraries Logo\">\n",
    "\n",
    "# Data in/and the Humanities\n",
    "**[NYU Abu Dhabi Winter Institute in Digital Humanities](https://wp.nyu.edu/widh/)**\n",
    "## Course Session \\#5-1 -- Text as Data Introduction\n",
    "\n",
    "**Nicholas Wolf**<br/>\n",
    "[ORCID 0000-0001-5512-6151](https://orcid.org/0000-0001-5512-6151)\n",
    "\n",
    "This lesson is licensed under a [Creative Commons Attribution-NonCommercial 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).\n",
    "\n",
    "**Overview**\n",
    "\n",
    "Humanists work a lot with texts. In fact, you might say that humanists *predominantly* work with texts. But texts are also filled with data -- or can themselves serve as data points in relation to other texts. In this exercise we'll look at a few ways that machine-actionable (i.e. computer readable) texts enable us to ask interesting questions about literary, cultural, or historical trends.\n",
    "\n",
    "**Materials**\n",
    "\n",
    " - A good text editor just as Notepad++ or TextWrangler.\n",
    " - An account in [Recognito](https://recogito.pelagios.org/), a project from the [Pelagios Commons](http://commons.pelagios.org/) group.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What Data Does Text Provide, and Why Does the Data Get So Big So Fast?\n",
    "\n",
    "We might consider roughly three types of data produced by a text or collection of texts that digital humanists typically work with:\n",
    "\n",
    "1. **Full text** data, consisting of words, images, or any item essential to convey the expression that is the essence of the text. This data will also include any resultant data describing the organization of these words, images, etc. (e.g. into paragraphs, pages, or sections) or the relationship of those words, images, etc. to each other (e.g. that one word is adjacent to another, or that a given word functions as a verb in its singular context. \n",
    "<br/>\n",
    "2. **Formal paratext**, or elements that accompany the full text, that accomplish things like giving the text a name (e.g. title), refers to its creator (author), organizes it (e.g. page numbers, headers/footers), provide its legal information (e.g. a title page), and the like.\n",
    "<br/>\n",
    "3. **Bibliographic information**, e.g. the labels used by information managers to manage that text. These may be a part of the paratext (e.g. ISBN number listed on a title page), but are often not part of the formal text itself but rather are added after its creation for organizational purposes only. These include call numbers, subject designations, tags, owners, etc.\n",
    "<br/>\n",
    "Obviously, there are potential overlaps for any of these three, but the idea here is to note the range for how texts might give rise to a dataset.\n",
    "\n",
    "Another caveat about text-as-data analysis is that full-text datasets can get very large very quickly. This \"big data\" aspect of text work is underappreciated. But consider that texts contain many words, and each word has potentially a large number of features (e.g. variables) that can measure it. For example, a word has ordered letters, a word has a unique sequence order in a book, a word belong to a particular sentence, a word has a preceding word, a word has a meaning, a word has a part of speech, a word may be capitalized, etc. etc. A big corpus of texts produces a lot of words, each with dozens of variable values that we could potentially attach to it.\n",
    "\n",
    "How many words? The HathiTrust corpus contains over 17 million texts. 17 million itself is not necessarily an intractable \"big data\" problem, but the 100 billion words in those 17 million texts are. Think of a 100-billion record datasheet with several dozen columns. For more on this problem, see Ben Schmidt's [\"Stable Random Projection: Lightweight, General-Purpose Dimensionality Reduction for Digitized Libraries,\"](https://culturalanalytics.org/article/11033) *Cultural Analytics* (3 Oct. 2018).\n",
    "\n",
    "We won't work with this big data here. We'll instead start small with looking at one particular way we might draw data from a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Textual Metadata: Data about a Full Text\n",
    "\n",
    "One of the common ways to build data out of a corpus of texts is to perform something like an annotation: attaching a data point to one or more functions/meanings of all or a subset of words in these texts. Two common ones are POS (parts of speech) tagging and one we can sample today, NER (named entity recognition).\n",
    "\n",
    "Before we try out some named entity recognition, let's reflect for a moment on how ubiquitous annotation -- often expressed as a markup of a text -- is in our everyday interactions with texts. Annotation is definitely not a product of machine-readable texts. Consider:\n",
    "\n",
    " - **Marginalia**: e.g. Cardiff Special Collections [examples of marginalia](https://scolarcardiff.wordpress.com/2012/04/30/a-well-used-book-marginalia-and-manuscript-notes-in-an-early-16th-century-herbal/)\n",
    " - **Scholarly editions**: e.g. Leo Kramer’s Hart Crane’s [“The Bridge”: An Annotated Edition](https://www.jstor.org/stable/j.ctt1c5chkg)\n",
    " - **HTML, XML, and other markup languages**: e.g.\n",
    " <pre>\n",
    "&lt;text&gt;\n",
    "&lt;stanza&gt;\n",
    "&lt;line&gt;FLOOD-TIDE below me! I see you face to face!&lt;/line&gt;\n",
    "&lt;line&gt;Clouds of the &lt;place&gt;west&lt;/place&gt; — sun there half an hour high — I see you also face to face.&lt;/line&gt;\n",
    "&lt;line&gt;Crowds of men and women attired in the usual costumes, how curious you are to me!&lt;/line&gt;\n",
    "&lt;line&gt;On the ferry-boats the hundreds and hundreds that cross, returning home, are more curious to me than you suppose,&lt;/line&gt;\n",
    "&lt;line>And you that shall cross from shore to shore years hence are more to me, and more in my meditations, than you might suppose.&lt;/line&gt;\n",
    "&lt;/stanza&gt;\n",
    "&lt;/text&gt;\n",
    "</pre>\n",
    " - **Paraphrasing, abstracts...**: virtually any kind of stand in for a text's content serve as data about the contents of that text.\n",
    " \n",
    "So our knowledge building is all about textual information summarily describing texts. We would like to gather that textual information itself and use it as a basis for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Named Entity Recognition\n",
    "\n",
    "To practice this, we'll take a machine readable text and collectivey decide how to annotate its named entities using Recognito.\n",
    "\n",
    "First, we need a text. A good source for machine-readable texts is [Project Gutenberg](https://www.gutenberg.org).\n",
    "\n",
    "Let's look at a randomly selected, but feature rich chapter from a book titled [*Peeps at Many Lands: Portugal*](https://drive.google.com/file/d/1rjpUks5KTQzggr0WKzuSefCV3ydGPyHM/view?usp=sharing) by Agnes M. Goodall, published in 1904. I've helpfully made [a plain text version of just chapter 3](https://drive.google.com/file/d/1rjpUks5KTQzggr0WKzuSefCV3ydGPyHM/view?usp=sharing) that you can download.\n",
    "\n",
    "Start up Recognito and let's upload our text. We'll work through this [short tutorial](https://recogito.pelagios.org/help/tutorial) on using Recognito together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analysis\n",
    "\n",
    "Once our markup is complete, let's look at download options and consider the possibilities of this newly produced data for:\n",
    "\n",
    " - Scholarly publishing (e.g. TEI-XML versions)\n",
    " - Plotting people, places, and events as representations of a text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
